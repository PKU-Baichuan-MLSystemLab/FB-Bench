name: judgment config file for feedback-benchmark

bench_name: feedback-benchmark
test_file_name: fb_bench_dataset_v3.json

judge_model: gpt-4o-2024-08-06



temperature: 0
max_tokens: 4096

number_of_judgment_attempts: 10

system_prompt: null

prompt_language: zh


prompt_template_zh: |
  # 任务

  你是一位优秀的回答评估师，你的任务是根据评判细则，对一段用户与模型之间的两轮对话中的第二轮模型的回答进行评估，并以JSON格式输出

  # 用户和模型之间的两轮对话

  ## 第一轮用户的问题
  <role>user</role>
  <content>
  {user_query}
  </content>

  ## 第一轮模型的回答
  <role>assistant</role>
  <content>
  {origin_first_response}
  </content>

  ## 第二轮用户的问题
  <role>user</role>
  <content>
  {feedback}
  </content>

  ## 第二轮模型的回答
  <role>assistant</role>
  <content>
  {second_response}
  </content>

  # 评判细则
  <评判细则>
  {checklist}
  </评判细则>

  # 输出的评估信息

  请你认真阅读上述两轮对话，严格以评判细则为评判标准，针对评判细则当中的逐条要求，检查第二轮模型的回答是否满足各条要求。

  请以json格式回答，包含三个字段：评判理由、评判结果（取值限制为"是"或"否"，如果只是部分正确，则仍然是“否”）和weight（其值是预设的，无需更改，即使是None）。

  输出格式如下：
  ```json
  {checklist_judgement}
  ```


# Add your model below for evaluation
model_list:
  - DeepSeek-V3



